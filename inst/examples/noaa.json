{
  "id": "neon4cast-gefs",
  "type": "Collection",
  "links": [
    {
      "rel": "items",
      "type": "application/json",
      "href": "https://data.ecoforecast.org/neon4cast-forecasts/stac/v1/catalog.json/items.json"
    },
    {
      "rel": "parent",
      "type": "application/json",
      "href": "https://data.ecoforecast.org/neon4cast-forecasts/stac/v1/catalog.json"
    },
    {
      "rel": "root",
      "type": "application/json",
      "href": "https://data.ecoforecast.org/neon4cast-forecasts/stac/v1/catalog.json"
    },
    {
      "rel": "self",
      "type": "application/json",
      "href": "https://data.ecoforecast.org/neon4cast-forecasts/stac/v1/noaa.json"
    },
    {
      "rel": "cite-as",
      "href": "https://doi.org/10.1002/fee.2616"
    },
    {
      "rel": "about",
      "href": "https://projects.ecoforecast.org/neon4cast-catalog/noaa-catalog.html",
      "type": "text/html",
      "title": "Organization Homepage"
    },
    {
      "rel": "license",
      "href": "https://creativecommons.org/publicdomain/zero/1.0/",
      "type": "text/html",
      "title": "public domain"
    },
    {
      "rel": "describedby",
      "href": "https://projects.ecoforecast.org/neon4cast-catalog/noaa-catalog.html",
      "title": "Example Notebook",
      "type": "text/html"
    }
  ],
  "title": "Ecological Forecasting Initiative - NOAA GEFS Forecast Snapshots",
  "assets": {
    "thumbnail": {
      "href": "https://data.ecoforecast.org/neon4cast-catalog/img/gefs_thumbnail.jpg",
      "type": "image/JPEG",
      "roles": [
        "thumbnail"
      ],
      "title": "GEFS temperature forecast thumbnail"
    },
    "parquet_items1": {
      "href": "https://sdsc.osn.xsede.org/bio230014-bucket01/noaa/gefs-v12/stage1/",
      "type": "application/x-parquet",
      "roles": [
        "stac-items"
      ],
      "title": "GEFS stage1 collection",
      "description": "`stage1` provides a parquet database partitioned on `reference_datetime` and `site_id` of data from the [NOAA Global Ensemble Forecast](https://registry.opendata.aws/noaa-gefs/) for [25 selected surface variables](https://github.com/eco4cast/gefs4cast/blob/main/inst/extdata/gefs-selected-bands.csv) at [NEON sites](https://www.neonscience.org/field-sites), extracted for all ensemble members. Please note that forecasts of the first 10 days (240 hours) use a 3 hr interval, while forecasts of days 11 through 35 days use a 6 hr interval (for v12).\n\n## Access\n\nUse `arrow` for quick remote access to the database. Specifying the `reference_datetime={date}` is optional but will give the best performance.\n\n### R \n\n```{r}\ndate <- \"2020-09-24\"\nstage <- \"stage1\"\npath <- \"neon4cast-drivers/noaa/gefs-v12\"\nbucket <- \"bio230014-bucket01\"\nendpoint <- \"https://sdsc.osn.xsede.org\"\n\nstage1 <- \n  glue::glue(\"{bucket}/{path}/{stage}/reference_datetime={date}\") |>\n  arrow::s3_bucket(endpoint_override = endpoint, anonymous = TRUE) |>\n  arrow::open_dataset()\n```\n\nNow we can use `dplyr` commands to subset the desired data without downloading the entire data product. \n\n```{r}\nlibrary(dplyr)\n\nq <- stage1 |> \n  filter(variable == \"TMP\",\n         site_id == \"BART\") |>\n  group_by(datetime) |>\n  summarise(temp = mean(prediction)) |>\n  arrange(datetime)\n\ndf <- q |> collect()\n```\n\n\n### Python\n\n```{python}\nimport pyarrow.dataset as ds\nfrom pyarrow import fs\n\ndate = \"2020-09-24\"\nstage = \"stage1\"\npath = \"neon4cast-drivers/noaa/gefs-v12\"\nbucket = \"bio230014-bucket01\"\nendpoint = \"https://sdsc.osn.xsede.org\"\ns3 = fs.S3FileSystem(endpoint_override = endpoint, anonymous = True)\n\ndset = ds.dataset(\n    f\"{bucket}/{path}/{stage}/reference_datetime={date}\",\n    filesystem=s3, partitioning=\"hive\")\n    \n```\n\n\n```{python}\nimport polars as pl\nq = (\n  pl.scan_pyarrow_dataset(dset)\n  .filter(pl.col(\"variable\") == \"TMP\")\n  .filter(pl.col(\"site_id\") == \"BART\")\n  .groupby(\"datetime\")\n  .agg(pl.col(\"prediction\").mean())\n  .sort(\"datetime\")\n)\ndf = q.collect()\n```\n\n"
    },
    "parquet_items2": {
      "href": "https://sdsc.osn.xsede.org/bio230014-bucket01/noaa/gefs-v12/stage1-stats/",
      "type": "application/x-parquet",
      "roles": [
        "stac-items"
      ],
      "title": "GEFS stage1-stats collection",
      "description": "`stage1-stats` provides raw data from the [NOAA Global Ensemble Forecast](https://registry.opendata.aws/noaa-gefs/) for [25 selected surface variables](https://github.com/eco4cast/gefs4cast/blob/main/inst/extdata/gefs-selected-bands.csv) at [NEON sites](https://www.neonscience.org/field-sites), extracted for the ensemble mean and spread. Please note that forecasts of the first 10 days (240 hours) use a 3 hr interval, while forecasts of days 11 through 35 days use a 6 hr interval (for v12).\n\n## Access\n\nUse `arrow` for quick remote access to the database. Specifying the `reference_datetime={date}` is optional but will give the best performance.\n\n### R \n\n```{r}\ndate <- \"2020-09-24\"\nstage <- \"stage1-stats\"\npath <- \"neon4cast-drivers/noaa/gefs-v12\"\nbucket <- \"bio230014-bucket01\"\nendpoint <- \"https://sdsc.osn.xsede.org\"\n\nstage1 <- \n  glue::glue(\"{bucket}/{path}/{stage}/reference_datetime={date}\") |>\n  arrow::s3_bucket(endpoint_override = endpoint, anonymous = TRUE) |>\n  arrow::open_dataset()\n```\n\nNow we can use `dplyr` commands to subset the desired data without downloading the entire data product. \n\n```{r}\nlibrary(dplyr)\n\nq <- stage1 |> \n  filter(variable == \"TMP\",\n         site_id == \"BART\")\n\ndf <- q |> collect()\n```\n\n\n### Python\n\n```{python}\nimport pyarrow.dataset as ds\nfrom pyarrow import fs\n\ndate = \"2020-09-24\"\nstage = \"stage1-stats\"\npath = \"neon4cast-drivers/noaa/gefs-v12\"\nbucket = \"bio230014-bucket01\"\nendpoint = \"https://sdsc.osn.xsede.org\"\ns3 = fs.S3FileSystem(endpoint_override = endpoint, anonymous = True)\n\ndset = ds.dataset(\n    f\"{bucket}/{path}/{stage}/reference_datetime={date}\",\n    filesystem=s3, partitioning=\"hive\")\n    \n```\n\n\n```{python}\nimport polars as pl\nq = (\n  pl.scan_pyarrow_dataset(dset)\n  .filter(pl.col(\"variable\") == \"TMP\")\n  .filter(pl.col(\"site_id\") == \"BART\")\n)\ndf = q.collect()\n```\n\n"
    },
    "parquet_items3": {
      "href": "https://sdsc.osn.xsede.org/bio230014-bucket01/noaa/gefs-v12/cfs/6hrly/00/",
      "type": "application/x-parquet",
      "roles": [
        "stac-items"
      ],
      "title": "CFS collection",
      "description": "`cfs` provides access to the NOAA long-range [Climate Forecast System](https://registry.opendata.aws/noaa-cfs/).  The CFS consists of 4 ensemble members. EFI snapshots the 6hr interval series.  In this series, the first ensemble member extends for a period of up to seven months, terminating on the latest last-day-of-the-month there-in.  The other ensembles extend up to 4 months, latest last-day-of-the-month.\nEFI provides access to a [selection of 25 bands](https://github.com/eco4cast/gefs4cast/blob/main/inst/extdata/cfs-selected-bands.csv) (note these do not always match bands available in GEFS forecast product).\nThese data are extracted from millions of individual GRIB2 files in the NOAA AWS catalog and distributes as a set of high-performance parquet databases partitioned on `reference_datetime` and `site_id` hosted by the [Open Storage Network](https://www.openstoragenetwork.org/).\n## Access\n\nUse `arrow` for quick remote access to the database. Specifying the `reference_datetime={date}` is optional but will give the best performance.\n\n### R \n\n```{r}\ndate <- \"2020-09-24\"\npath <- \"neon4cast-drivers/noaa/cfs/6hrly/00\"\nbucket <- \"bio230014-bucket01\"\nendpoint <- \"https://sdsc.osn.xsede.org\"\n\ndset <- \n  glue::glue(\"{bucket}/{path}/reference_datetime={date}\") |>\n  arrow::s3_bucket(endpoint_override = endpoint, anonymous = TRUE) |>\n  arrow::open_dataset()\n```\n\nNow we can use `dplyr` commands to subset the desired data without downloading the entire data product. \n\n```{r}\nlibrary(dplyr)\n\nq <- dset |> \n  filter(variable == \"TMP_2m\",\n         site_id == \"BART\") |>\n  group_by(datetime) |>\n  summarise(temp = mean(prediction)) |>\n  arrange(datetime)\n\ndf <- q |> collect()\n```\n\n\n### Python\n\n```{python}\nimport pyarrow.dataset as ds\nfrom pyarrow import fs\n\ndate = \"2020-09-24\"\npath = \"neon4cast-drivers/noaa/cfs/6hrly/00\"\nbucket = \"bio230014-bucket01\"\nendpoint = \"https://sdsc.osn.xsede.org\"\ns3 = fs.S3FileSystem(endpoint_override = endpoint, anonymous = True)\n\ndset = ds.dataset(\n    f\"{bucket}/{path}/reference_datetime={date}\",\n    filesystem=s3, partitioning=\"hive\")\n    \n```\n\n\n```{python}\nimport polars as pl\nq = (\n  pl.scan_pyarrow_dataset(dset)\n  .filter(pl.col(\"variable\") == \"TMP_2m\")\n  .filter(pl.col(\"site_id\") == \"BART\")\n  .groupby(\"datetime\")\n  .agg(pl.col(\"prediction\").mean())\n  .sort(\"datetime\")\n)\ndf = q.collect()\n```\n\n"
    }
  },
  "extent": {
    "spatial": {
      "bbox": [
        [
          -156.6194,
          17.9696,
          -66.7987,
          71.2824
        ]
      ]
    },
    "temporal": {
      "interval": [
        [
          "2017-01-01T00:00:00Z",
          "2023-04-26T00:00:00Z"
        ]
      ]
    }
  },
  "license": "CC0-1.0",
  "keywords": ["Forecasting", "Data", "Weather", "NOAA"],
  "providers": [
    {
      "url": "https://www.emc.ncep.noaa.gov/emc/pages/numerical_forecast_systems/gefs.php",
      "name": "NOAA Forecasts",
      "roles": [
        "producer",
        "processor",
        "licensor"
      ]
    },
    {
      "url": "https://registry.opendata.aws/noaa-gefs/",
      "name": "AWS Open Data Registry",
      "roles": [
        "host"
      ]
    }
  ],
  "description": "The [Ecological Forecasting Initiative](https://ecoforecast.org) extracts and distributes the forecasts produced by NOAA's 35-day, 31-ensemble member forecast system for [25 variables](https://github.com/eco4cast/gefs4cast/blob/main/inst/extdata/gefs-selected-bands.csv)  at surface-height for [81 NEON sites](https://www.neonscience.org/field-sites). Forecasts are provided each day at midnight UTC, dating back from 2017-01-01 to present. These data are extracted from millions of individual GRIB2 files in the NOAA AWS catalog and distributes as a set of high-performance parquet databases partitioned on `reference_datetime` and `site_id` hosted by the [Open Storage Network](https://www.openstoragenetwork.org/).\n\n\nPlease note that for measurements pertaining to fluxes, such as accumulated precipitation, these are given for the 6-hr period prior to the `datetime` for horizons divisible by 6, and for a 3-hr period for others.\n\n\nEFI provides several distinct products derived from GEFS forecasts covering different use cases and different versions. \n\n- GEFS Version 12 data covers forecasts produced since 2020-09-24.\n\n- GEFS Version 11 data covers forecasts produced between 2017-01-01 and 2020-09-23, and includes only 21 ensemble members, a uniform 6 hr sampling interval, and extends only 16 days into the future.\n\n- `stage1` provides raw data for 25 selected surface variables at NEON sites, extracted for all ensemble members. Please note that forecasts of the first 10 days (240 hours) use a 3 hr interval, while forecasts of days 11 through 35 days use a 6 hr interval (for v12). \n\n- `stage1-stats` provides the same data coverage drawn from the average and spread data (`geavg` and `gespr`).  This product is only available for v12, though summary statistics can also be calculated across ensemble by the user.\n\n- `pseudo` series constructs \"pseudo-measurements\" from the initial values or nearest forecasts made at each site for each datetime.  Because NOAA releases new forecasts every 6 hours, this are comprised of the 0-horizon values at midnight (00), 06, 12, 18 hours each day, along with 3hr and 6hr horizon forecasts, which contain necessary information for calculating flux (accumulation) variables not included on the 0-horizon forecasts. This data extraction forms the input data for the `stage3` product, which provides a more easily used format.  These historical predictions can be useful in model fitting / model calibration in lieu of actual meterological measurements.  (While less accurate than ground truth measurements, these allows a modeler to avoid systematic bias from switching on training with measured data to predictions based on NOAA-model forecasts). \n\nAll data are provided as-is without guarantee of accuracy. Please\nconsult original data products and generation scripts for details.\n",
  "stac_version": "1.0.0",
  "table_columns": [
    {
      "name": "reference_datetime",
      "description": "ISO 8601(ISO 2019) datetime the forecast starts from (a.k.a. issue time); Only needed if more than one reference_datetime is stored in a single file. Forecast lead time (horizon) is thus datetime minus reference_datetime.",
      "type": "string"
    },
    {
      "name": "site_id",
      "description": "For forecasts that are not on a spatial grid, use of a site dimension that maps to a more detailed geometry (points, polygons, etc.) is allowable. In general this would be documented in the external metadata (e.g., a look-up table that provides lon and lat);",
      "type": "string"
    },
    {
      "name": "family",
      "description": "probability distribution. sample trajectories may be denoted \"ensemble\" or \"sample,\".  NOAA summary statistics use \"spread\"",
      "type": "string"
    },
    {
      "name": "ensemble",
      "description": "ensemble member",
      "type": "string"
    },
    {
      "name": "variable",
      "description": "abbreviation for variable measured, see <https://github.com/eco4cast/gefs4cast/blob/main/inst/extdata/gefs-selected-bands.csv>",
      "type": "string"
    },
    {
      "name": "prediction",
      "description": "predicted forecast value for the variable specified",
      "type": "double"
    },
    {
      "name": "datetime",
      "description": "ISO 8601(ISO 2019) datetime being predicted. This variable was called time before v0.5 of the EFIconvention. For time-integrated variables (e.g., cumulative net primary productivity), one should specify the start_datetime and end_datetime as two variables, instead of the single datetime. If this is not provided the datetime is assumed to be the MIDPOINT of the integration period.",
      "type": "datetime"
    }
  ],
  "stac_extensions": [
    "https://stac-extensions.github.io/scientific/v1.0.0/schema.json",
    "https://stac-extensions.github.io/item-assets/v1.0.0/schema.json",
    "https://stac-extensions.github.io/table/v1.2.0/schema.json"
  ],
  "publications": {
    "doi": "https://doi.org/10.1002/fee.2616",
    "citation": "R Quinn Thomas, Carl Boettiger, Cayelan C Carey, Michael C Dietze, Leah R Johnson, Melissa A Kenney, Jason S McLachlan, Jody A Peters, Eric R Sokol, Jake F Weltzin, Alyssa Willson, Whitney M Woelmer, Challenge contributors"
  }
}
